# ğŸ¤– ShaulNet - Robo-Shaul-TTS

[![DOI](https://zenodo.org/badge/993479487.svg)](https://doi.org/10.5281/zenodo.15609915)

## About the Robo-Shaul Challenge

The **Robo-Shaul Challenge** was a competition held from February to May 2023, aiming to develop the first open-source Hebrew text-to-speech (TTS) engine that replicates the voice of journalist and podcast host Shaul Amsterdamski. The initiative was documented in three podcast episodes, detailing the process and results.

As part of the challenge, a Hebrew single-speaker dataset named **SASPEECH** was created, consisting of approximately 30 hours of Amsterdamski's recordings. This dataset, along with a benchmark TTS system, was presented at INTERSPEECH 2023.

For more details, visit the [official Robo-Shaul website](https://www.roboshaul.com/).

## ShaulNet

**ShaulNet** is our solution to the [Robo-Shaul Challenge](https://www.roboshaul.com/): a flexible, multilingual Text-to-Speech (TTS) system designed to synthesize natural-sounding Hebrew speech from raw text using a modular and configurable architecture.

Our solution requires the use of fully diacritized text in Hebrew.

This repository integrates and builds upon several outstanding open-source projects, including:

* [Matcha-TTS](https://github.com/shivammehta25/Matcha-TTS)
* [RingFormer](https://github.com/seongho608/RingFormer)
* [Tacotron2](https://github.com/NVIDIA/tacotron2)
* [HiFi-GAN](https://github.com/jik876/hifi-gan)
* [BigVGAN](https://github.com/NVIDIA/BigVGAN)
* [Griffin-Lim](https://pytorch.org/audio/main/generated/torchaudio.transforms.GriffinLim.html)
* [WaveGlow](https://pytorch.org/hub/nvidia_deeplearningexamples_waveglow/)
* [Distill-MOS](https://github.com/microsoft/Distill-MOS?tab=readme-ov-file)


## ğŸš€ Features

* ğŸ™ï¸ High-quality text-to-speech synthesis
* ğŸŒ Full Hebrew language support, including diacritics and phonetic normalization
* ğŸ§  Built on state-of-the-art models and vocoders
* ğŸ§ª Modular architecture for research, experimentation, and production


## ğŸ”Š Audio Sample

Below is an example output generated by the ShaulNet system from Hebrew input text:

https://github.com/user-attachments/assets/99595ed7-a8d6-4a11-8606-781766a3ee03


https://github.com/user-attachments/assets/dd5da098-66af-482c-96b8-30ac3a339a53


## ğŸ“ Basic Usage

```bash
# Run TTS using the config file (choose model/vocoder inside it)
python inference.py --text "×©×Ö¸×œ×•Ö¹× ×¢×•Ö¹×œÖ¸×" --model matcha --vocoder hifigan --checkpoint checkpoints/matcha_tts/logs/train/ljspeech/runs/2025-06-02_14-11-39/checkpoints/checkpoint_epoch=2679.ckpt   --output-file outputs/generated.wav

````

Edit the `conf/config.yaml` file to customize the input text, model, vocoder, and output:

```yaml
inference:
  text: "××” ×§×•×¨×”, ×©××•×œ?"
  output_path: "outputs/shaul.wav"
```

## ğŸ› ï¸ Project Structure

```
ShaulNet/
â”‚
â”œâ”€â”€ config/                             # YAML configuration files for Hydra (model/vocoder selection)
â”œâ”€â”€ data/                               # Raw or processed datasets (e.g., text inputs or training data)
â”œâ”€â”€ Data_Creation_scripts/              # Scripts for text preprocessing (e.g., Hebrew-to-English conversion)
â”œâ”€â”€ download_pretrained_models_scripts/ # Scripts to download pretrained models (e.g., Tacotron2, WaveGlow)
â”œâ”€â”€ filelists/                          # File lists for model training (e.g., train.txt, val.txt)
â”œâ”€â”€ Matcha_TTS/                         # Matcha-TTS model codebase (training, synthesis, utils)
â”œâ”€â”€ Plotting/                           # Utility scripts for visualizing mel-spectrograms and alignments
â”œâ”€â”€ Preprocess/                         # Data preprocessing pipeline (cleaners, format converters, etc.)
â”œâ”€â”€ pretrained_models/                  # Folder containing downloaded/pretrained TTS and vocoder models.
â”œâ”€â”€ RingFormer/                         # Optional RingFormer model codebase (if neeeded).
â”œâ”€â”€ tracatron2/                         # Tacotron2 model codebase (architecture, training, inference).
â”œâ”€â”€ .gitignore                          # Git ignore rules (e.g., checkpoints, logs, outputs)
â”œâ”€â”€ LICENSE                             # Open-source license (e.g., MIT)
â”œâ”€â”€ inference.py                        # Main script to perform TTS inference via Hydra-configurable pipeline
â””â”€â”€ README.md                           # This file
```

## âœ… TODO

* [x] Upload the project code to GitHub.
* [x] Write basic documentation in the README.
* [x] Integrate automated testing and CI pipelines.
* [ ] Add MOS evaluation using Distill-MOS.
* [ ] Add a checkpoint files.
* [ ] Add the dataset files after the preprocess.
* [ ] Add more audio samples to the README.
* [ ] Improve support for undiacritized Hebrew text.
* [ ] Add automatic validation using WER metric based on Whisper model.

## ğŸ™ Acknowledgments

* This project is based in part on the **English-to-Hebrew preprocessing** logic from [maxmelichov/Text-To-speech](https://github.com/maxmelichov/Text-To-speech).
* We would like to thank the developers and researchers of all the referenced projects above for their open-source contributions to the speech synthesis community.

## ğŸ“œ License

This project is licensed under the MIT License. See [LICENSE](LICENSE) for details.


## ğŸ“¬ Contact

[![Gmail](https://img.shields.io/badge/Gmail-D14836?logo=gmail&logoColor=white)](mailto:Avishai11900@gmail.com)

[![LinkedIn](https://img.shields.io/badge/LinkedIn-blue?logo=linkedin&logoColor=white)](https://www.linkedin.com/in/avishai-weizman/)

[![GitHub](https://img.shields.io/badge/GitHub-100000?logo=github&logoColor=white)](https://github.com/avishai111)




